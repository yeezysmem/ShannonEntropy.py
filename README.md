# ShannonEntropy.py
 
determine the amount of information contained in a text message from your last name, first name and patronymic. Calculate the average entropy per character of the encoded message and the average length of code combinations required to encode each character of the message. Find the amount of information contained in the encoded message, absolute and relative redundancy of the message when encoding each letter of the message by one byte.

To develop a program in a high-level programming language to calculate the entropy and the amount of information contained in text files of arbitrary length, the maximum possible entropy at the same probability of alphabet symbols, absolute and relative redundancy. When entering text data, provide two modes of code input: input from the keyboard, as well as entering data from a text file using single-byte code tables.

Using the program developed at runtime, investigate the dependence of entropy on text length, as well as the dependence of entropy on language. To do this, using available automatic translation programs, prepare identical text files in different languages (e.g., English, Ukrainian, Russian) of different lengths, for which to conduct research.
